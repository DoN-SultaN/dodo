#!/bin/bash
set -euo pipefail

#######################################################################
# Script for building Twitter OSS libraries based on either their 
# develop branches or from locally checked out copies.
#
# See: print_usage function for usage
#######################################################################
VERSION="0.0.1"

UTIL_COMMANDS="./sbt +test:compile +publishLocal"
declare "util_name=util"
declare "util_commands=$UTIL_COMMANDS"

OSTRICH_COMMANDS="./sbt +test:compile +publishLocal"
declare "ostrich_name=ostrich"
declare "ostrich_commands=$OSTRICH_COMMANDS"

SCROOGE_CORE_COMMANDS="./sbt +scrooge-publish-local/publishLocal;./sbt ++2.10.6 scrooge-generator/publishLocal scrooge-sbt-plugin/publishLocal"
declare "scroogecore_name=scrooge"
declare "scroogecore_commands=$SCROOGE_CORE_COMMANDS"

FINAGLE_COMMANDS="./sbt +test:compile +publishLocal"
declare "finagle_name=finagle"
declare "finagle_commands=$FINAGLE_COMMANDS"

SCROOGE_COMMANDS="./sbt +test:compile scrooge-generator-tests/test:compile"
declare "scrooge_name=scrooge"
declare "scrooge_commands=$SCROOGE_COMMANDS"

TWITTER_SERVER_COMMANDS="./sbt +test:compile +publishLocal"
declare "twitterserver_name=twitter-server"
declare "twitterserver_commands=$TWITTER_SERVER_COMMANDS"

FINATRA_COMMANDS="./sbt +test:compile +publishLocal"
declare "finatra_name=finatra"
declare "finatra_commands=$FINATRA_COMMANDS"

## To clean up remove:
#   $DODO_DIRECTORY/caches
#   $DODO_DIRECTORY/clones
#   $DODO_DIRECTORY/builds
DODO_DIRECTORY="$HOME/.dodo"
cache_home=$DODO_DIRECTORY/caches
clone_home=$DODO_DIRECTORY/clones
build_home=$DODO_DIRECTORY/builds

# Actual DAG list for building (order is important)
projects=( "util" "ostrich" "scroogecore" "finagle" "scrooge" "twitter-server" "finatra" )
# Validation project list
project_list=( "util" "ostrich" "finagle" "scrooge" "twitter-server" "finatra" )

# Initialize defaults
build_all=false         # build all projects in the DAG list
dry_run=false           # output but don't execute the build commands
remote=true             # if we should build projects from remote Github URIs
run_tests=true          # if we should run tests when building projects
include_project=false   # include building the given project argument; useful for scripted testing of libraries
offline=false           # if the build should use a downloaded sbt-launch jar; the url is given in the next param
sbt_version=""          # [offline only] version of sbt-launch jar.
proxy_url=""            # [offline only] download the sbt-launch jar from a given url
sbt_jar=""              # [offline only] location of the downloaded sbt-launch jar.
scala_version=""        # if set only build the projects with the given version (instead of cross-compiling with +)
verbose=false           # set -x

# Note: does not work if the message contains an array
function log {
	local severity=$1
	local message=$2
	local uppercaseSeverity=$(echo $severity | awk '{print toupper($0)}')
	echo "[$uppercaseSeverity] $message"
}

function contains_project {
  local element=$1
  for project in "${project_list[@]}"; do [[ "$project" == "$element" ]] && return 0; done
  return 1
}

function array_get { 
    local array=$1 index=$2
    local i="${array}_$index"
    printf '%s' "${!i}"
}

function run_commands {
	local project=$1
	local commands=$2
	commands_hash=$(echo "$commands" | openssl dgst -md5)

	local build=true
	if [[ "$remote" = true ]] && [[ -f "$build_home/$project/$commands_hash" ]]; then
		# there's a cached build by commands hash file, check it
		build_sha=$(cat $build_home/$project/$commands_hash)
		local_sha=$(latest_local_sha)
		if [[ "$build_sha" == "$local_sha" ]]; then
			build=false
		fi
	fi

	if [[ "$build" = true ]]; then
		local to_replace="test:compile"
		if [[ "$run_tests" = true ]]; then
			commands="${commands//$to_replace/test}"
		fi
		if [[ "$offline" = true ]]; then
			to_replace_command="./sbt "
			if [[ "$project" == "scrooge" ]]; then
			    replacement_command="./sbt -sbt-jar $sbt_jar "
			else 
			    replacement_command="cp $sbt_jar ./sbt-launch.jar;./sbt "
			fi
			commands="${commands//$to_replace_command/$replacement_command}"
		fi
		IFS=';' read -ra commandsArray <<< "$commands"
		for command in "${commandsArray[@]}"; do
			if [[ -n "$scala_version" ]]; then
				if [[ $command != *"++"* ]]; then
					# if we were passed a scala version and the command doesn't already explicity set a scala version
					command="${command//+/}" # remove + for cross-compile
					command="${command//.\/sbt /./sbt ++$scala_version }" # add scala version
				fi
			fi
		    log "info" "$command"
		    if [[ "$dry_run" != true ]]; then 
		    	eval $command
		    fi
		done
		record_build $project $commands_hash
	else
		log "info" "Using previously built results..."
		log "info" " "
		if [[ "$remote" = true ]]; then 
			details="built-sha @ $(cat $build_home/$project/$commands_hash)"
			log "info" "--- $details ---"
		fi
	fi
}

# record a hash of the commands run against the SHA of the remote repo it ran against.
function record_build {
	if [[ "$remote" = true ]] && [[ "$dry_run" != true ]]; then
		local project=$1
		local commands_hash=$2
		if [[  ! -f "$build_home/$project" ]]; then mkdir -p  $build_home/$project; fi
		latest_local_sha > $build_home/$project/$commands_hash
	fi
}

# Assumes you are in the correct directory when you run this
function latest_local_sha {
	git rev-parse develop
}

function record_latest_sha {
	local project=$1
	## store the lastest SHA
	latest_local_sha > $cache_home/$project
}

function clone {
	if [[ "$remote" = true ]]; then
		cd $clone_home
		if [ ! -d "$clone_home/$project_name" ]; then
			# doesn't yet exist clone and store SHA
			log "info" "------------------------------------------------------------------------"
			log "info" "Cloning develop branch for repository: $project_name"
			log "info" "------------------------------------------------------------------------"
			git clone https://github.com/twitter/$project_name.git --branch develop --depth=1
			cd $project_name
			record_latest_sha $project_name
			log "info" " "
		else
			cd $project_name
			# a clone already exists; is it up to date?
			if [ -f "$cache_home/$project_name" ]; then
				# read cache
				local_sha=$(cat $cache_home/$project_name)
			else
				# read local directory
				local_sha=$(latest_local_sha)
			fi
			remote_sha=$(git ls-remote https://github.com/twitter/$project_name.git -- refs/heads/develop | cut -f1)
			if [[ "$local_sha" != "$remote_sha" ]]; then
				log "info" "------------------------------------------------------------------------"
				log "info" "Updating previously cloned develop branch for repository: $project_name"
				log "info" "------------------------------------------------------------------------"
				# update clone and store SHA
				cd $clone_home/$project_name
				git pull
				record_latest_sha $project_name
			fi
			log "info" " "
		fi
		cd $clone_home
	fi
}

function build {	
	local project=$1
	local project_name="$(array_get ${project//-/} name)"
	clone $project_name
	# cd into project directory; run commands; cd back
	cd $project_name

	details="local"
	if [[ "$remote" = true ]]; then details="git-sha @ $(cat $cache_home/$project_name)"; fi
	log "info" "------------------------------------------------------------------------"
	log "info" "Building $project"
	log "info" "------------------------------------------------------------------------"
	log "info" " "
	log "info" "--- $details ---"
	log "info" " "
	run_commands $project_name "$(array_get ${project//-/} commands)"
	cd - > /dev/null 2>&1
}

# When we are offline we need to be able to download an sbt-launch.jar from
# an accessible URL (typically an internal repository).
function download_sbt_launch_jar {
	sbt_jar=`pwd`/sbt-launch-${sbt_version}.jar
	# clean up any previously downloaded sbt launch jar
	if [ -f "$sbt_jar" ]; then
		rm $sbt_jar
	fi
	# download new sbt launch jar
	if [[ -z "$proxy_url" ]]; then
		log "error" "No proxy url could be found for downloading the sbt-launch jar." >&2
		print_usage >&2
		exit 1
	fi
	local url="$proxy_url/org/scala-sbt/sbt-launch/${sbt_version}/sbt-launch-${sbt_version}.jar"
	wget $url
	sbt_jar=`pwd`/sbt-launch-${sbt_version}.jar
	ls -l $sbt_jar
}

function check_offline {
	# if we're offline, download the sbt-launch.jar to use in building.
	if [[ "$offline" = true ]]; then
		download_sbt_launch_jar	
	fi	
}

function build_projects {
	local project=$1
	local to_build=()
	check_offline
	
	log "info" "Determining projects..."
	# loop until we find the matching project or all
	for current in ${projects[@]}; do
		if [ "$current" = "$project" ] && [[ "$build_all" != true ]]; then
			break
		else
			to_build+=("$current")
		fi
	done
	# if we're including the given project build it as well
	if [[ "$include_project" = true ]] && [[ "$build_all" != true ]]; then
		to_build+=("$project")
	fi

	# Start build of projects
	local details=""
	if [[ "$dry_run" = true ]]; then details=" (dry-run)"; fi
	log "info" "------------------------------------------------------------------------"
	log "info" "Dodo Build Order:$details"
	if [ "${#to_build[@]}" -gt "0" ]; then
		printf '[INFO]   %s\n' "${to_build[@]}"
		for project in ${to_build[@]}; do
			build $project
			log "info" " "
		done
	else
		log "info" "  -- empty --"
		log "info" " "
	fi
}

function set_up {
	if [ ! -d "$cache_home" ]; then
		mkdir -p $cache_home
	fi
	if [ ! -d "$clone_home" ]; then
		mkdir -p $clone_home
	fi
	if [ ! -d "$build_home" ]; then
		mkdir -p $build_home
	fi
}

function print_usage {
	echo "USAGE: $0 --local --no-test --include --scala-version 2.11.7 <project>"
	echo "Options:
  --all:            Build all projects in the DAG list (overrides --include). Default: false.
  --include:	    Include building of the given project. Default: false.
  --no-test:	    Do not run tests (will still compile tests via test:compile). 
                    Default: false (run tests).
  --scala-version   If set, do not cross-compile instead use this specific version for building all projects.
                    Default: unset (cross-compile).
  --clone-dir		Directory into which to clone remotes. Default: $HOME/.dodo/clones
  --local:          Build source from local filesystem instead of Github. 
                    Default: false (use Github sources).
  --proxy:	 	    Base URL from which to resolve artifacts when working offline, (e.g., the sbt-launch.jar),
                    Example: --proxy https://my.internal.company.repo/sbt-repo. NOTE: you MUST set 
                    --local and --sbt-version with this option. Default: unset.
  --sbt-version:    The sbt version to use when downloading the sbt launch jar. Default: unset.
  --dry-run: 	    Output, but do not excute the sbt build commands. If using remotes 
                    they will still be cloned. Default: false.
  --verbose:        Run in verbose mode. Default: false.
  --help:           Print usage."
}

function check_arg {
	local arg=$1
	if [[ $arg == --* ]]; then
		log "error" "Unrecognized argument: $arg" >&2
		print_usage >&2
		exit 1;
	fi
}

function echo_set_options {
	if [[ "$verbose" = true ]]; then
		log "info" "  remote: $remote"
		log "info" "  run tests: $run_tests"
		log "info" "  include: $include_project"
		if [[ -n "$scala_version" ]]; then echo "  scala version: $scala_version"; fi
		if [[ "$offline" = true ]]; then
			log "info" "  offline: $offline"
			log "info" "  proxy: $proxy_url"
			log "info" "  sbt version: $sbt_version"
		fi
	fi
}

# BEGIN: OPTION PARSING AND VALIDATION ------------------------------------------------------------------
if [[ -z "$@" ]]; then print_usage >&2; exit 1; fi
# Simple option parsing. We could use getopts but rather use "long"
# names only. And this is position-agnostic to the options, e.g.,
# these options can occur before or after the main arguments.
shift_count="0"
for arg in "$@"; do
  shift
  case "$arg" in
    "--all")			build_all=true ;;
    "--include")		include_project=true ;;
    "--no-test") 		run_tests=false  ;;
    "--scala-version") 	scala_version=$1; ((shift_count+=1)) ;;
    "--clone-dir")		clone_home=$1; ((shift_count+=1)) ;;
    "--local") 			remote=false ;;
    "--proxy") 			offline=true;proxy_url=$1; ((shift_count+=1)) ;;    
    "--sbt-version") 	sbt_version=$1; ((shift_count+=1)) ;;
    "--dry-run")		dry_run=true ;;
    "--verbose")		verbose=true ;;
    "--help") 			print_usage >&2; exit ;;	
    *)        			check_arg $arg;set -- "$@" "$arg"
  esac
done
if [[ "$offline" = true ]] && [[ -z "$sbt_version" ]]; then
	log "error" "Must supply an sbt version with \"--sbt-version\" when using \"--proxy URL\"." >&2
	print_usage >&2
	exit 1
fi
if [[ "$offline" = true ]] && [[ "$remote" = true ]]; then
	log "error" "Cannot specify \"--proxy URL\" without also setting \"--local\"." >&2
	print_usage >&2
	exit 1
fi
# read and validate $project
project="unset"
if [[ "$build_all" != true ]]; then
	if [[ -z "$@" ]]; then print_usage >&2; exit 1; fi
	 # need to shift by the number of params set above with values
	if [[ "$shift_count" != "0" ]]; then shift $shift_count; fi
	# Read in remaining option -- which should be the project name.
	project="$1"
	if ! contains_project $project; then
		echo "[ERROR] Project must be one of: \"${project_list[@]}\"" >&2
		print_usage >&2
		exit 1
	fi
fi
if [[ "$build_all" = true ]] && [[ "$include_project" = true ]];then
	log "warn" "Ignoring \"--include\" flag as \"--all\" was specified." >&2
fi
if [[ "$verbose" = true ]]; then set -x; fi
# END: OPTION PARSING AND VALIDATION --------------------------------------------------------------------

# BEGIN: EXECUTE BUILD ----------------------------------------------------------------------------------
START=`date +%s`
set_up
echo_set_options
build_projects $project

END=`date +%s`
FORMATTED=`date "+%YT%H:%M:%S%z"`
DIFF=$(echo "$END - $START" | bc)
log "info" "------------------------------------------------------------------------"
log "info" "BUILD SUCCESS"
log "info" "------------------------------------------------------------------------"
log "info" "Total time: $DIFF s"
log "info" "Finished at: $FORMATTED"
log "info" "Dodo version v$VERSION"
log "info" "------------------------------------------------------------------------"
# END: EXECUTE BUILD ------------------------------------------------------------------------------------